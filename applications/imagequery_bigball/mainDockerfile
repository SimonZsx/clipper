FROM tensorflow/tensorflow:1.12.0-gpu-py3 
RUN apt-get update

# /container would contains:
# c0_entryContainer c1_speechRecognition/ c2_imageCaptionGenerator/ c3_nlpMappingGenerator/ c4_questionAnswering/ main.py
 
###### Install dependencies ######
### for c1 
RUN apt-get install wget zip unzip python3 python3-pip -y
RUN pip3 install SpeechRecognition
RUN apt-get install -y swig libpulse-dev libasound2-dev
RUN pip3 install pocketsphinx
RUN apt-get install curl -y
RUN apt-get install ffmpeg -y
RUN pip3 install pydub
RUN apt-get install ffmpeg libavcodec-extra -y
RUN pip3 install glob3

### for c2 
RUN pip3 install numpy nltk
RUN python3 -m nltk.downloader all
RUN apt install wget

### for c3 
RUN pip3 install nltk numpy textacy
RUN python3 -m nltk.downloader all
RUN pip3 install spacy
RUN python3 -m spacy download en_core_web_sm

######################################

###### Copy files and run scripts ######

### for c0
COPY c0_entryContainer/app /container/c0_entryContainer

### for c1 
ADD c1_speechRecognition/app /container/c1_speechRecognition
ADD c1_speechRecognition/data /container/c1_speechRecognition/data

# RUN chmod 777 /container/c1_speechRecognition/data/dataset3/downloadDataset.sh
# RUN /container/c1_speechRecognition/data/dataset3/downloadDataset.sh
# RUN mv $(find / -name speech-accent-archive.zip) /container/c1_speechRecognition/data/dataset3
# RUN unzip /container/c1_speechRecognition/data/dataset3/speech-accent-archive.zip -d /container/c1_speechRecognition/data/dataset3
# RUN unzip -qq /container/c1_speechRecognition/data/dataset3/recordings.zip -d /container/c1_speechRecognition/data/dataset3/
# RUN chmod 777 /container/c1_speechRecognition/data/dataset3/rename.sh
# RUN /container/c1_speechRecognition/data/dataset3/rename.sh
# RUN python3 /container/c1_speechRecognition/data/dataset3/truncate.py

### for c2 
# copy files into image
ADD c2_imageCaptionGenerator/app /container/c2_imageCaptionGenerator/
ADD c2_imageCaptionGenerator/captionData /container/c2_imageCaptionGenerator/captionData
ADD c2_imageCaptionGenerator/im2txt/ /container/c2_imageCaptionGenerator/im2txt/
ADD c2_imageCaptionGenerator/im2txt/ops/ /container/c2_imageCaptionGenerator/ops/
 
# download pre-trained models 
RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/model/downloadModels.sh
RUN /container/c2_imageCaptionGenerator/im2txt/model/downloadModels.sh
RUN mv /notebooks/newmodel.ckpt-2000000.meta /container/c2_imageCaptionGenerator/im2txt/model
RUN mv /notebooks/newmodel.ckpt-2000000.data-00000-of-00001 /container/c2_imageCaptionGenerator/im2txt/model

# download datasets, untar and reindex images.
# RUN wget --progress=bar:force http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz
# RUN mv /notebooks/101_ObjectCategories.tar.gz /container/c2_imageCaptionGenerator/im2txt/data/imageDataset
# RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/untar.sh 
# RUN /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/untar.sh 
# RUN chmod 777 /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/rename.sh 
# RUN /container/c2_imageCaptionGenerator/im2txt/data/imageDataset/rename.sh

### for c3 
ADD c3_nlpMappingGenerator/app /container/c3_nlpMappingGenerator

### for c4
ADD c4_questionAnswering/app /container/c4_questionAnswering

# for main.py
ADD main.py /container

# /container nows contains: 
# c0_entryContainer c1_speechRecognition/ c2_imageCaptionGenerator/ c3_nlpMappingGenerator/ c4_questionAnswering/ main.py
#########################################################

# Crucial
WORKDIR /container

# CMD ["python", "/container/closure.py"]
CMD ["python3", "/container/main.py"]

EXPOSE 10000
