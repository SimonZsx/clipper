# docker build -f ./imagequery_w_proxy/Dockerfile1 -t imagequery_w_proxy:c1 .
# docker run -p 8000:8000 --runtime=nvidia -it imagequery_w_proxy:c1

# From Mozilla github repo Dockerfile beginning
FROM nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential \
        curl \
        wget \
        git \
        python3 \
        python3-dev \
        python3-pip \
        python3-wheel \
        python3-numpy \
        libcurl3-dev  \
        ca-certificates \
        gcc \
        sox \
        libsox-fmt-mp3 \
        htop \
        nano \
        swig \
        cmake \
        libboost-all-dev \
        zlib1g-dev \
        libbz2-dev \
        liblzma-dev \
        locales \
        pkg-config \
        libsox-dev \
        openjdk-8-jdk \
        bash-completion \
        g++ \
        unzip

# By YY:
RUN apt-get install -y git-lfs 
RUN pip3 install --upgrade deepspeech-gpu

# Download pre-trained model
WORKDIR /container/models
RUN wget --progress=bar:force https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
RUN tar xvfz deepspeech-0.5.1-models.tar.gz

# Copy files
WORKDIR /container/app
ADD imagequery_w_proxy/c1_ds/app .

WORKDIR /container/data
ADD imagequery_w_proxy/c1_ds/data .


# container/ will have predict.py, data/
# ADD imagequery_w_proxy/c1_speechRecognition/app /container/
# ADD imagequery_w_proxy/c1_speechRecognition/data /container/data

# dataset1 
# dataset source: http://festvox.org/cmu_arctic/
# RUN wget --progress=bar:force http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_awb_arctic-0.95-release.zip
# RUN mv $(find / -name cmu_us_awb_arctic-0.95-release.zip) /container/data/dataset1
# RUN chmod 777 /container/data/dataset1/unzipRename.sh
# RUN /container/data/dataset1/unzipRename.sh

# dataset2
# reference: https://groups.csail.mit.edu/sls/downloads/flickraudio/index.cgi
# RUN wget --progress=bar:force https://groups.csail.mit.edu/sls/downloads/flickraudio/downloads/flickr_audio.tar.gz
# RUN mv $(find / -name flickr_audio.tar.gz) /container/data/dataset2
# RUN chmod 777 /container/data/dataset2/untarRename.sh 
# RUN /container/data/dataset2/untarRename.sh

# dataset3
# download reference: https://www.kaggle.com/general/6604
# dataset refernce: https://www.kaggle.com/rtatman/speech-accent-archive/
# RUN chmod 777 /container/data/dataset3/downloadDataset.sh
# RUN /container/data/dataset3/downloadDataset.sh
# RUN mv $(find / -name speech-accent-archive.zip) /container/data/dataset3
# RUN unzip /container/data/dataset3/speech-accent-archive.zip -d /container/data/dataset3
# # /container/data/dataset3 now contains:reading-passage.txt, recordings.zip, speakers_all.csv
# RUN unzip -qq /container/data/dataset3/recordings.zip -d /container/data/dataset3/
# RUN chmod 777 /container/data/dataset3/rename.sh
# RUN /container/data/dataset3/rename.sh
# RUN python3 /container/data/dataset3/truncate.py

# ADD grpc/app/container_entry.sh /container/
# ADD grpc/app/server.py /container/
# ADD grpc/app/model_pb2_grpc.py /container/
# ADD grpc/app/model_pb2.py /container/
# ADD grpc/app/proxy_pb2_grpc.py /container/
# ADD grpc/app/proxy_pb2.py /container/

WORKDIR /container/app
# CMD ["python3", "predict.py"]

# CMD ["/container/container_entry.sh", "c1", "/container/server.py"]

EXPOSE 8000